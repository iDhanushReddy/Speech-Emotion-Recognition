{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":639622,"sourceType":"datasetVersion","datasetId":316368}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n     \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating a Label Dataser","metadata":{}},{"cell_type":"code","source":"paths = []\nlabels = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        labels.append(label.lower())\nprint('Dataset is Loaded')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Forming a new Data file","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['speech'] = paths\ndf['label'] = labels\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring the data Data Analysis","metadata":{}},{"cell_type":"code","source":"sns.countplot(data = df, x = 'label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def waveplot(data, sr, emotion):\n    plt.figure(figsize=(10,4))\n    plt.title(emotion, size=20)\n    librosa.display.waveshow(data, sr=sr)\n    plt.show()\n    \ndef spectogram(data, sr, emotion):\n    x = librosa.stft(data)\n    xdb = librosa.amplitude_to_db(abs(x))\n    plt.figure(figsize=(10,4))\n    plt.title(emotion, size=20)\n    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.colorbar()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'fear'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'angry'\npath = np.array(df['speech'][df['label']==emotion])[1]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'disgust'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'neutral'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'sad'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'happy'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'ps'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'happy'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"def extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_mfcc(df['speech'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_mfcc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [x for x in X_mfcc]\nX = np.array(X)\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## input split\nX = np.expand_dims(X, -1)\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['label']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = y.toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create LSTM Model","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n\nmodel = Sequential([\n    LSTM(256, return_sequences=False, input_shape=(40,1)),\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(X, y, validation_split=0.2, epochs=10, batch_size=64 ,shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Results","metadata":{}},{"cell_type":"code","source":"epochs = list(range(10))\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, label='train accuracy')\nplt.plot(epochs, val_acc, label='val accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs, loss, label='train loss')\nplt.plot(epochs, val_loss, label='val loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_size = int(0.35 * len(X))\nx_val = X[-val_size:]\ny_val = y[-val_size:]\n\ny_pred = model.predict(x_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_classes = np.argmax(y_pred, axis=1)\ny_val_classes = np.argmax(y_val, axis=1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\nimport numpy as np\n\nprecision = precision_score(y_val_classes, y_pred_classes, average='weighted')  # Use 'weighted' for multi-class\nrecall = recall_score(y_val_classes, y_pred_classes, average='weighted')\nf1 = f1_score(y_val_classes, y_pred_classes, average='weighted')\n\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')\nprint(f'F1 Score: {f1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Precision, Recall, F1 Score\ndef plot_metrics(precision, recall, f1):\n    metrics = ['Precision', 'Recall', 'F1 Score']\n    scores = [precision, recall, f1]\n\n    plt.figure(figsize=(8, 5))\n    plt.bar(metrics, scores, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n    plt.title('Precision, Recall, F1 Score')\n    plt.ylim(0, 1)\n    plt.ylabel('Score')\n    plt.show()\n\n# Call the function to plot precision, recall, f1\nplot_metrics(precision, recall, f1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}